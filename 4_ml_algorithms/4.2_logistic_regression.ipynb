{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b773d3b2-0bc0-41ca-8660-507d84fffabe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07204d26-948c-47de-a661-bee71b540e09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../environment/prepare_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfe6f484-6feb-4bb4-99b2-79480cf68943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Logistic Regression â€” Telco Churn Classification\n",
    "\n",
    "This notebook will cover:\n",
    "- Loading features for a churn prediction problem\n",
    "- Training and tuning a logistic regression model using Spark ML\n",
    "- Tracking experiments and results with MLflow\n",
    "- Visualizing model performance with ROC curves and confusion matrices\n",
    "\n",
    "**Why logistic regression?**\n",
    "- It's a gold standard for interpretable binary classification\n",
    "- Fast, robust, and a great baseline for many problems\n",
    "- Easy to explain to business stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64e6f3f8-bd80-4432-83d7-ccce539f99dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow.spark\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import Pipeline\n",
    "from mlflow.models import infer_signature\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"telco-churn-pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3c0096b-39c9-4c6f-97d5-e3ae5386442d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load Feature Table\n",
    "\n",
    "We use features engineered in the previous workshop. If the feature table is missing, we automatically re-run the feature engineering notebook. This ensures reproducibility and a clean ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fd226ee-098a-46dc-9a06-0b6848f34504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data loading and preparation as a function for reusability\n",
    "\n",
    "def load_feature_table():\n",
    "    feature_table_name = \"ai_ml_in_practice.telco_customer_churn_silver.telco_silver_vectors\"\n",
    "\n",
    "    df = None\n",
    "    try:\n",
    "        df = spark.table(feature_table_name)\n",
    "        logger.info(f\"Loaded feature table: {feature_table_name}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    if df is None:\n",
    "        logger.warning(\"Feature table not found. Re-running feature engineering notebooks to create features.\")\n",
    "        get_ipython().run_line_magic('run', '../2_data_preparations/2.1_telco_raw_to_bronze.ipynb')\n",
    "        get_ipython().run_line_magic('run', '../2_data_preparations/2.1_telco_bronze_to_silver.ipynb')\n",
    "        get_ipython().run_line_magic('run', '../3_feature_engineering/3.1_telco_feature_table.ipynb')\n",
    "        df = spark.table(feature_table_name)\n",
    "    if df is None:\n",
    "        raise RuntimeError(\"Feature dataframe could not be found or created.\")\n",
    "    return df\n",
    "\n",
    "df = load_feature_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f79d57f0-2add-473e-96f7-cc13e5628049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Data Quality Checks & Preparation\n",
    "\n",
    "Before modeling, always check that your label and features are present and correctly typed. This is a key standard for robust ML pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e147300d-24b9-4d7c-8871-169f74716c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data sanity checks\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "if 'churn' not in df.columns or 'customer_features' not in df.columns:\n",
    "    raise ValueError(\"Required columns 'churn' and 'customer_features' not found in feature table.\")\n",
    "df = df.withColumn('churn', col('churn').cast('double'))\n",
    "logger.info(f\"Total rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "700bd5f2-07ac-4b5d-a71b-cceece2a31fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "We split the data into training and test sets (80/20). This is a standard practice to evaluate model generalization and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6ca938e-581b-4676-95f2-8f4e670f844e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train/test split as a function\n",
    "\n",
    "def split_data(df, train_ratio=0.8, seed=42):\n",
    "    train_df, test_df = df.randomSplit([train_ratio, 1-train_ratio], seed=seed)\n",
    "    logger.info(f\"Train: {train_df.count()}, Test: {test_df.count()}\")\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29f3be1b-c9b2-4c83-8f40-d340101f2926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. MLFlow Setup and Model Training\n",
    "\n",
    "We use MLFlow to track all experiments, parameters, and results. Logistic regression is trained with cross-validation and hyperparameter tuning. All metrics and artifacts are logged for full reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b726786a-5d96-42e5-92c8-3ddc0a74e63b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model training, tuning, and MLflow logging\n",
    "\n",
    "def train_and_log(train_df, test_df, experiment_name=\"telco_logistic_regression\"):\n",
    "    lr = LogisticRegression(featuresCol='customer_features', labelCol='churn')\n",
    "    param_grid = (ParamGridBuilder()\n",
    "                  .addGrid(lr.regParam, [0.0, 0.01, 0.1])\n",
    "                  .addGrid(lr.elasticNetParam, [0.0, 0.5])\n",
    "                  .addGrid(lr.maxIter, [10, 50])\n",
    "                  .build())\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='churn', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
    "    multiclass_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"churn\",\n",
    "        predictionCol=\"prediction\"\n",
    "    )\n",
    "    cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "    with mlflow.start_run(run_name=\"logistic_regression_cv\") as run:\n",
    "        # Train a model\n",
    "        cv_model = cv.fit(train_df)\n",
    "        best_model = cv_model.bestModel\n",
    "\n",
    "        # Evaluate the model using the test set\n",
    "        predictions = best_model.transform(test_df)\n",
    "        acc = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "        prec = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"weightedPrecision\"})\n",
    "        rec = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"weightedRecall\"})\n",
    "        roc_auc = evaluator.evaluate(predictions)\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": float(acc),\n",
    "            \"precision\": float(prec),\n",
    "            \"recall\": float(rec),\n",
    "            \"roc_auc\": float(roc_auc)\n",
    "        })\n",
    "        logger.info(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, ROC_AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        # Get predictions from the best model\n",
    "        pdf = predictions.select('prediction', 'churn', 'probability').toPandas()\n",
    "        y_true = pdf['churn'].astype(int)\n",
    "        y_score = pdf['probability'].apply(lambda v: v[1])\n",
    "\n",
    "        # ROC Curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        ax.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('Receiver Operating Characteristic (ROC)')\n",
    "        ax.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.close(fig)\n",
    "        mlflow.log_figure(fig, \"roc_curve.png\")\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, pdf['prediction'].astype(int))\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.close(fig)\n",
    "        mlflow.log_figure(fig, \"confusion_matrix.png\")\n",
    "\n",
    "        # Feature importance\n",
    "        importances = cv_model.bestModel.coefficients.toArray()\n",
    "        attrs = train_df.schema['customer_features'].metadata['ml_attr']['attrs']\n",
    "        feature_labels = []\n",
    "        for attr_type in [\"numeric\", \"binary\", \"nominal\"]:\n",
    "            if attr_type in attrs:\n",
    "                feature_labels.extend([a[\"name\"] for a in attrs[attr_type]])\n",
    "        coef_df = pd.DataFrame({'Feature': feature_labels, 'Coefficient': importances})\n",
    "        coef_df = coef_df.sort_values('Coefficient', key=abs, ascending=False)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        coef_df.plot.bar(x='Feature', y='Coefficient', ax=ax, legend=False, color='teal')\n",
    "        ax.set_title('Feature Importances (Logistic Regression Coefficients)')\n",
    "        ax.set_ylabel('Coefficient Value')\n",
    "        plt.tight_layout()\n",
    "        plt.close(fig)\n",
    "        mlflow.log_figure(fig, \"feature_importance.png\")\n",
    "\n",
    "        # Save model to MLflow Model Registry\n",
    "        signature = infer_signature(train_df.select(\"customer_features\"), predictions)\n",
    "\n",
    "        mlflow.spark.log_model(\n",
    "            best_model,\n",
    "            artifact_path='telco_churn_logreg',\n",
    "            signature=signature,\n",
    "            registered_model_name='ai_ml_in_practice.telco_customer_churn_silver.telco_churn_logreg_model',\n",
    "            dfs_tmpdir=\"/Volumes/ai_ml_in_practice/telco_customer_churn_silver/mlflow_tmp\"\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model logged and registered as telco_churn_logreg_model\")\n",
    "        return best_model, predictions\n",
    "\n",
    "best_model, predictions = train_and_log(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bd195a9-5d9f-4d57-9157-d3e0af7b4bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Batch Inference and Model Loading\n",
    "\n",
    "In production, you often need to load a model and run batch inference. Here is how you do it with MLflow and SparkML library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb3ee4a5-a526-485c-be8c-9b8df2996f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.spark.load_model(\n",
    "    \"models:/ai_ml_in_practice.telco_customer_churn_silver.telco_churn_logreg_model/1\",\n",
    "    dfs_tmpdir=\"/Volumes/ai_ml_in_practice/telco_customer_churn_silver/mlflow_tmp\"\n",
    ")\n",
    "\n",
    "# Batch inference example\n",
    "inference_df = loaded_model.transform(test_df)\n",
    "display(inference_df.select('prediction', 'probability'))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.2_logistic_regression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
